"""
æ‰¹é‡æ¨ç†è„šæœ¬ - å®Œæ•´1000æ­¥DDPMé‡‡æ ·
å¤„ç†Datasetä¸­æ‰€æœ‰çš„rawæ–‡ä»¶ï¼ˆtrain/val/testï¼‰
"""

import torch
import numpy as np
from pathlib import Path
import argparse
from typing import List, Tuple
from tqdm import tqdm
import warnings
import time
from datetime import datetime

from model import ConditionalDiffWave
from diffusion import GaussianDiffusion


class FullStepBatchDenoiser:
    """
    æ‰¹é‡å»å™ªæ¨ç†å™¨ - å®Œæ•´1000æ­¥DDPMé‡‡æ ·
    
    Args:
        model_path: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
        device: æ¨ç†è®¾å¤‡
        segment_length: ç‰‡æ®µé•¿åº¦ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        hop_length: è·³è·ƒé•¿åº¦ï¼ˆçª—å£é‡å æ§åˆ¶ï¼‰
        use_amp: æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦åŠ é€Ÿæ¨ç†
        baseline_correction: æ˜¯å¦è¿›è¡ŒåŸºçº¿æ ¡æ­£
    """
    
    def __init__(
        self,
        model_path: str,
        device: str = 'cuda',
        segment_length: int = 2048,
        hop_length: int = 1024,
        use_amp: bool = True,
        baseline_correction: bool = True
    ):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.segment_length = segment_length
        self.hop_length = hop_length
        self.use_amp = use_amp
        self.baseline_correction = baseline_correction
        
        print("="*80)
        print("æ‰¹é‡æ¨ç†é…ç½® (å®Œæ•´1000æ­¥DDPM)")
        print("="*80)
        print(f"æ¨¡å‹è·¯å¾„: {model_path}")
        print(f"æ¨ç†è®¾å¤‡: {self.device}")
        print(f"ç‰‡æ®µé•¿åº¦: {segment_length} samples ({segment_length/500:.2f}s @ 500Hz)")
        print(f"è·³è·ƒé•¿åº¦: {hop_length} samples (é‡å : {(1 - hop_length/segment_length)*100:.1f}%)")
        print(f"é‡‡æ ·æ­¥æ•°: 1000 (å®Œæ•´DDPMï¼Œæ— åŠ é€Ÿ)")
        print(f"æ··åˆç²¾åº¦: {use_amp}")
        print(f"åŸºçº¿æ ¡æ­£: {baseline_correction}")
        print("="*80)
        print()
        
        # åˆ›å»ºæ¨¡å‹
        print("åŠ è½½æ¨¡å‹...")
        model = ConditionalDiffWave(
            in_channels=2,
            out_channels=1,
            residual_channels=256,
            num_layers=30,
            dilation_cycle=10,
            time_emb_dim=512
        ).to(self.device)
        
        # æ³¨æ„ï¼šè¿™é‡Œsampling_timesteps=Noneè¡¨ç¤ºä½¿ç”¨å®Œæ•´çš„1000æ­¥
        self.diffusion = GaussianDiffusion(
            model=model,
            timesteps=1000,
            beta_start=1e-4,
            beta_end=0.02,
            loss_type='hybrid',
            sampling_timesteps=None  # ä½¿ç”¨å®Œæ•´timesteps
        ).to(self.device)
        
        # åŠ è½½æƒé‡
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=True)
        model.load_state_dict(checkpoint['model_state_dict'])
        
        self.diffusion.eval()
        
        # åˆ›å»ºHannçª—å£ç”¨äºoverlap-add
        self.window = torch.hann_window(segment_length).to(self.device)
        
        print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ!")
        if 'epoch' in checkpoint:
            print(f"  è®­ç»ƒè½®æ¬¡: {checkpoint['epoch']}")
        if 'val_loss' in checkpoint:
            print(f"  éªŒè¯æŸå¤±: {checkpoint['val_loss']:.6f}")
        print()
    
    def _normalize_segment(self, segment: np.ndarray) -> Tuple[np.ndarray, float, float]:
        """Instance Normalization"""
        mean = np.mean(segment)
        std = np.std(segment)
        
        if std < 1e-8:
            std = 1.0
        
        normalized = (segment - mean) / std
        return normalized, mean, std
    
    def _denormalize_segment(self, segment: np.ndarray, mean: float, std: float) -> np.ndarray:
        """åå½’ä¸€åŒ–"""
        return segment * std + mean
    
    def _baseline_correct(self, signal: np.ndarray) -> np.ndarray:
        """åŸºçº¿æ ¡æ­£ï¼šç§»é™¤DCåˆ†é‡"""
        return signal - np.mean(signal)
    
    @torch.no_grad()
    def denoise_segment(self, raw_segment: np.ndarray) -> np.ndarray:
        """
        å¯¹å•ä¸ªç‰‡æ®µè¿›è¡Œå»å™ªï¼ˆå®Œæ•´1000æ­¥ï¼‰
        
        Args:
            raw_segment: åŸå§‹ç‰‡æ®µ [segment_length]
            
        Returns:
            denoised_segment: å»å™ªåçš„ç‰‡æ®µ [segment_length]
        """
        # å½’ä¸€åŒ–
        normalized, mean, std = self._normalize_segment(raw_segment)
        
        # è½¬æ¢ä¸ºtensor
        condition = torch.from_numpy(normalized).float().unsqueeze(0).unsqueeze(0).to(self.device)
        
        # æ¨ç†ï¼ˆå®Œæ•´1000æ­¥ï¼Œä¸ä½¿ç”¨DDIMåŠ é€Ÿï¼‰
        if self.use_amp:
            with torch.cuda.amp.autocast():
                denoised = self.diffusion.sample(
                    condition, 
                    ddim_sampling=False,  # ä¸ä½¿ç”¨DDIMï¼Œå®Œæ•´é‡‡æ ·
                    show_progress=False   # å…³é—­å•ä¸ªç‰‡æ®µçš„è¿›åº¦æ¡
                )
        else:
            denoised = self.diffusion.sample(
                condition,
                ddim_sampling=False,
                show_progress=False
            )
        
        # è½¬æ¢å›numpy
        denoised_np = denoised.squeeze().cpu().numpy()
        
        # åå½’ä¸€åŒ–
        denoised_denorm = self._denormalize_segment(denoised_np, mean, std)
        
        # åŸºçº¿æ ¡æ­£
        if self.baseline_correction:
            denoised_denorm = self._baseline_correct(denoised_denorm)
        
        return denoised_denorm
    
    def denoise_full_signal(self, raw_signal: np.ndarray, show_progress: bool = True) -> np.ndarray:
        """
        ä½¿ç”¨overlap-addæ–¹æ³•å¯¹å®Œæ•´ä¿¡å·è¿›è¡Œå»å™ª
        
        Args:
            raw_signal: å®Œæ•´çš„åŸå§‹ä¿¡å· [T]
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            
        Returns:
            denoised_signal: å»å™ªåçš„å®Œæ•´ä¿¡å· [T]
        """
        signal_length = len(raw_signal)
        
        if signal_length < self.segment_length:
            warnings.warn(
                f"ä¿¡å·é•¿åº¦ ({signal_length}) çŸ­äºç‰‡æ®µé•¿åº¦ ({self.segment_length})ã€‚ä½¿ç”¨é›¶å¡«å……ã€‚"
            )
            padded = np.pad(raw_signal, (0, self.segment_length - signal_length), mode='constant')
            denoised = self.denoise_segment(padded)
            return denoised[:signal_length]
        
        # åˆå§‹åŒ–è¾“å‡ºç¼“å†²åŒº
        output = np.zeros(signal_length, dtype=np.float32)
        weights = np.zeros(signal_length, dtype=np.float32)
        
        # è®¡ç®—çª—å£æ•°é‡
        num_windows = int(np.ceil((signal_length - self.segment_length) / self.hop_length)) + 1
        
        # Hannçª—å£
        window_np = np.hanning(self.segment_length).astype(np.float32)
        
        # æ»‘åŠ¨çª—å£å¤„ç†
        iterator = range(num_windows)
        if show_progress:
            iterator = tqdm(iterator, desc='  å¤„ç†ç‰‡æ®µ', unit='window', leave=False)
        
        for i in iterator:
            start = i * self.hop_length
            end = start + self.segment_length
            
            # å¤„ç†æœ€åä¸€ä¸ªçª—å£
            if end > signal_length:
                start = signal_length - self.segment_length
                end = signal_length
                
                if start < (i - 1) * self.hop_length + self.segment_length:
                    continue
            
            # æå–å¹¶å»å™ª
            segment = raw_signal[start:end]
            denoised_segment = self.denoise_segment(segment)
            
            # åº”ç”¨çª—å£å‡½æ•°
            denoised_windowed = denoised_segment * window_np
            
            # Overlap-add
            output[start:end] += denoised_windowed
            weights[start:end] += window_np
        
        # å½’ä¸€åŒ–
        weights = np.maximum(weights, 1e-8)
        output = output / weights
        
        # æœ€ç»ˆåŸºçº¿æ ¡æ­£
        if self.baseline_correction:
            output = self._baseline_correct(output)
        
        return output
    
    def process_file(self, raw_path: Path, output_path: Path) -> bool:
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶
        
        Args:
            raw_path: åŸå§‹æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            success: æ˜¯å¦æˆåŠŸå¤„ç†
        """
        try:
            # åŠ è½½ä¿¡å·
            raw_signal = np.load(raw_path).astype(np.float32)
            
            if raw_signal.ndim > 1:
                raw_signal = raw_signal.squeeze()
            
            # å»å™ª
            start_time = time.time()
            denoised_signal = self.denoise_full_signal(raw_signal, show_progress=True)
            elapsed = time.time() - start_time
            
            # ä¿å­˜
            output_path.parent.mkdir(parents=True, exist_ok=True)
            np.save(output_path, denoised_signal)
            
            # ç»Ÿè®¡ä¿¡æ¯
            signal_duration = len(raw_signal) / 500  # 500Hz
            print(f"    âœ“ å®Œæˆ | ä¿¡å·: {signal_duration:.1f}s | è€—æ—¶: {elapsed:.1f}s | é€Ÿåº¦æ¯”: {signal_duration/elapsed:.2f}x")
            
            return True
            
        except Exception as e:
            print(f"    âœ— é”™è¯¯: {e}")
            return False
    
    def batch_process_dataset(
        self,
        dataset_dir: str,
        output_dir: str,
        subsets: List[str] = ['train', 'val', 'test']
    ):
        """
        æ‰¹é‡å¤„ç†Datasetä¸­çš„æ‰€æœ‰rawæ–‡ä»¶
        
        Args:
            dataset_dir: Datasetç›®å½•è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            subsets: è¦å¤„ç†çš„å­é›†åˆ—è¡¨
        """
        dataset_path = Path(dataset_dir)
        output_path = Path(output_dir)
        
        print("="*80)
        print("å¼€å§‹æ‰¹é‡æ¨ç†")
        print("="*80)
        print(f"æ•°æ®é›†è·¯å¾„: {dataset_path}")
        print(f"è¾“å‡ºè·¯å¾„: {output_path}")
        print(f"å¤„ç†å­é›†: {subsets}")
        print()
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶
        all_files = []
        for subset in subsets:
            raw_dir = dataset_path / subset / 'raw'
            if not raw_dir.exists():
                print(f"âš  è­¦å‘Š: {raw_dir} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue
            
            # åªå¤„ç†ésegmentæ–‡ä»¶ï¼ˆé¿å…é‡å¤å¤„ç†åˆ‡ç‰‡æ•°æ®ï¼‰
            files = [f for f in raw_dir.glob('*.npy') if 'segment' not in f.name]
            all_files.extend([(f, subset) for f in files])
        
        if len(all_files) == 0:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶ï¼")
            return
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶å¾…å¤„ç†\n")
        
        # ç»Ÿè®¡ä¿¡æ¯
        success_count = 0
        fail_count = 0
        total_start_time = time.time()
        
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for idx, (raw_path, subset) in enumerate(all_files, 1):
            print(f"[{idx}/{len(all_files)}] {subset}/{raw_path.name}")
            
            # æ„é€ è¾“å‡ºè·¯å¾„ï¼ˆä¿æŒç›¸åŒçš„ç›®å½•ç»“æ„ï¼‰
            output_file_path = output_path / subset / 'denoised' / raw_path.name.replace('_raw.npy', '_denoised.npy')
            
            # å¤„ç†æ–‡ä»¶
            success = self.process_file(raw_path, output_file_path)
            
            if success:
                success_count += 1
            else:
                fail_count += 1
            
            print()
        
        # æ€»ç»“
        total_elapsed = time.time() - total_start_time
        print("="*80)
        print("æ‰¹é‡æ¨ç†å®Œæˆ")
        print("="*80)
        print(f"æ€»æ–‡ä»¶æ•°: {len(all_files)}")
        print(f"æˆåŠŸ: {success_count}")
        print(f"å¤±è´¥: {fail_count}")
        print(f"æ€»è€—æ—¶: {total_elapsed/60:.1f} åˆ†é’Ÿ")
        print(f"å¹³å‡æ¯æ–‡ä»¶: {total_elapsed/len(all_files):.1f} ç§’")
        print(f"ç»“æœä¿å­˜è‡³: {output_path}")
        print("="*80)


def main():
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡EEGä¿¡å·å»å™ªæ¨ç† - å®Œæ•´1000æ­¥DDPMé‡‡æ ·'
    )
    
    parser.add_argument(
        '--model', 
        type=str, 
        required=True,
        help='æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ (.pt file)'
    )
    parser.add_argument(
        '--dataset_dir', 
        type=str, 
        default='../Dataset',
        help='Datasetç›®å½•è·¯å¾„ (é»˜è®¤: ../Dataset)'
    )
    parser.add_argument(
        '--output_dir', 
        type=str, 
        default='../Dataset_denoised_full1000',
        help='è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: ../Dataset_denoised_full1000)'
    )
    parser.add_argument(
        '--subsets', 
        type=str, 
        nargs='+', 
        default=['train', 'val', 'test'],
        help='è¦å¤„ç†çš„å­é›† (é»˜è®¤: train val test)'
    )
    parser.add_argument(
        '--segment_length', 
        type=int, 
        default=2048,
        help='ç‰‡æ®µé•¿åº¦ï¼Œå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ (é»˜è®¤: 2048)'
    )
    parser.add_argument(
        '--hop_length', 
        type=int, 
        default=1024,
        help='è·³è·ƒé•¿åº¦ï¼Œæ§åˆ¶overlap (é»˜è®¤: 1024, 50%%é‡å )'
    )
    parser.add_argument(
        '--device', 
        type=str, 
        default='cuda',
        help='æ¨ç†è®¾å¤‡ (é»˜è®¤: cuda)'
    )
    parser.add_argument(
        '--no_amp', 
        action='store_true',
        help='ç¦ç”¨æ··åˆç²¾åº¦'
    )
    parser.add_argument(
        '--no_baseline_correction', 
        action='store_true',
        help='ç¦ç”¨åŸºçº¿æ ¡æ­£'
    )
    
    args = parser.parse_args()
    
    # æ‰“å°å¼€å§‹æ—¶é—´
    print(f"\nå¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # åˆ›å»ºå»å™ªå™¨
    denoiser = FullStepBatchDenoiser(
        model_path=args.model,
        device=args.device,
        segment_length=args.segment_length,
        hop_length=args.hop_length,
        use_amp=not args.no_amp,
        baseline_correction=not args.no_baseline_correction
    )
    
    # æ‰§è¡Œæ‰¹é‡æ¨ç†
    denoiser.batch_process_dataset(
        dataset_dir=args.dataset_dir,
        output_dir=args.output_dir,
        subsets=args.subsets
    )
    
    # æ‰“å°ç»“æŸæ—¶é—´
    print(f"\nç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")


if __name__ == '__main__':
    main()
