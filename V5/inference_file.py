"""
æ–‡ä»¶çº§æ¨ç†è„šæœ¬
æ”¯æŒå•æ–‡ä»¶æˆ–ç›®å½•æ‰¹é‡æ¨ç†ï¼Œä¿å­˜é™å™ªåçš„æ—¶åŸŸä¿¡å·
"""
import sys
from pathlib import Path
import argparse
import torch
import numpy as np
from tqdm import tqdm
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from models.uar_acssnet import UAR_ACSSNet
from configs.default import get_default_config


def load_model(checkpoint_path, device='cuda', baseline_mode=None):
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    
    Args:
        checkpoint_path: checkpointæ–‡ä»¶è·¯å¾„
        device: è®¾å¤‡
        baseline_mode: æ˜¯å¦ä½¿ç”¨baselineæ¨¡å¼ï¼ˆNoneåˆ™ä»checkpointè·å–ï¼‰
    
    Returns:
        model: åŠ è½½å¥½çš„æ¨¡å‹
        cfg: é…ç½®å­—å…¸
    """
    print(f"\nğŸ“¦ Loading checkpoint from: {checkpoint_path}")
    ckpt = torch.load(checkpoint_path, map_location=device)
    
    # ä»checkpointè·å–é…ç½®ï¼ˆå¦‚æœæœ‰ï¼‰æˆ–ä½¿ç”¨é»˜è®¤é…ç½®
    if 'cfg' in ckpt:
        cfg = ckpt['cfg']
        print("âœ“ Using config from checkpoint")
    else:
        cfg = get_default_config()
        print("âœ“ Using default config")
    
    # åˆ›å»ºæ¨¡å‹
    bm = cfg.get("baseline_mode", False) if baseline_mode is None else baseline_mode
    model = UAR_ACSSNet(
        segment_length=cfg.get("segment_length", 2048),
        unet_base_ch=cfg.get("unet_base_ch", 32),
        unet_levels=cfg.get("unet_levels", 4),
        spec_channels=cfg.get("spec_channels", 64),
        acss_depth=cfg.get("acss_depth", 3),
        num_freq_bins=cfg.get("num_freq_bins", 101),
        dropout=cfg.get("dropout", 0.0),
        baseline_mode=bm,
    ).to(device)
    
    # åŠ è½½æƒé‡
    model.load_state_dict(ckpt['model_state_dict'])
    model.eval()
    
    print(f"âœ“ Loaded model from epoch {ckpt.get('epoch', 'unknown')}")
    val_loss = ckpt.get('val_loss', None)
    if isinstance(val_loss, (float, int)):
        print(f"âœ“ Best val loss: {val_loss:.6f}")
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"âœ“ Total parameters: {total_params:,}")
    print(f"âœ“ Mode: {'Baseline U-Net' if model.baseline_mode else 'Full UAR-ACSSNet'}")
    
    return model, cfg


def normalize_signal(signal, method='zscore'):
    """
    å½’ä¸€åŒ–ä¿¡å·
    
    Args:
        signal: è¾“å…¥ä¿¡å· (numpy array)
        method: å½’ä¸€åŒ–æ–¹æ³• ('zscore', 'minmax', 'none')
    
    Returns:
        normalized_signal: å½’ä¸€åŒ–åçš„ä¿¡å·
        stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸ï¼ˆç”¨äºåå½’ä¸€åŒ–ï¼‰
    """
    if method == 'zscore':
        mean = np.mean(signal)
        std = np.std(signal)
        if std < 1e-8:
            std = 1.0
        normalized = (signal - mean) / std
        stats = {'mean': mean, 'std': std, 'method': 'zscore'}
    elif method == 'minmax':
        min_val = np.min(signal)
        max_val = np.max(signal)
        if max_val - min_val < 1e-8:
            normalized = signal
        else:
            normalized = (signal - min_val) / (max_val - min_val)
        stats = {'min': min_val, 'max': max_val, 'method': 'minmax'}
    else:  # 'none'
        normalized = signal
        stats = {'method': 'none'}
    
    return normalized, stats


def denormalize_signal(signal, stats):
    """
    åå½’ä¸€åŒ–ä¿¡å·
    
    Args:
        signal: å½’ä¸€åŒ–åçš„ä¿¡å·
        stats: å½’ä¸€åŒ–ç»Ÿè®¡ä¿¡æ¯
    
    Returns:
        åŸå§‹å°ºåº¦çš„ä¿¡å·
    """
    method = stats.get('method', 'none')
    
    if method == 'zscore':
        return signal * stats['std'] + stats['mean']
    elif method == 'minmax':
        return signal * (stats['max'] - stats['min']) + stats['min']
    else:
        return signal


def segment_signal(signal, segment_length, stride):
    """
    å°†é•¿ä¿¡å·åˆ†å‰²æˆå¤šä¸ªç‰‡æ®µ
    
    Args:
        signal: è¾“å…¥ä¿¡å· (N,) æˆ– (1, N)
        segment_length: ç‰‡æ®µé•¿åº¦
        stride: æ»‘çª—æ­¥é•¿
    
    Returns:
        segments: (num_segments, 1, segment_length)
        num_segments: ç‰‡æ®µæ•°é‡
    """
    if signal.ndim == 1:
        signal = signal[np.newaxis, :]  # (1, N)
    
    n_samples = signal.shape[1]
    
    if n_samples <= segment_length:
        # ä¿¡å·é•¿åº¦ä¸è¶³ï¼Œå¡«å……
        padded = np.zeros((1, segment_length))
        padded[:, :n_samples] = signal
        return padded[np.newaxis, :, :], 1, n_samples
    
    # æ»‘çª—åˆ†å‰²
    segments = []
    start = 0
    while start + segment_length <= n_samples:
        segment = signal[:, start:start + segment_length]
        segments.append(segment)
        start += stride
    
    # å¤„ç†æœ€åä¸€ä¸ªç‰‡æ®µï¼ˆå¦‚æœéœ€è¦ï¼‰
    if start < n_samples:
        last_segment = np.zeros((1, segment_length))
        remaining = n_samples - start
        last_segment[:, :remaining] = signal[:, start:]
        segments.append(last_segment)
    
    segments = np.stack(segments, axis=0)  # (num_segments, 1, segment_length)
    return segments, len(segments), n_samples


def reconstruct_signal(segments, original_length, stride):
    """
    ä»åˆ†å‰²çš„ç‰‡æ®µé‡å»ºå®Œæ•´ä¿¡å·ï¼ˆä½¿ç”¨é‡å å¹³å‡ï¼‰
    
    Args:
        segments: (num_segments, 1, segment_length)
        original_length: åŸå§‹ä¿¡å·é•¿åº¦
        stride: æ»‘çª—æ­¥é•¿
    
    Returns:
        reconstructed: (original_length,)
    """
    num_segments, _, segment_length = segments.shape
    
    # å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µ
    if num_segments == 1:
        return segments[0, 0, :original_length]
    
    # é‡å å¹³å‡é‡å»º
    reconstructed = np.zeros(original_length)
    counts = np.zeros(original_length)
    
    start = 0
    for i in range(num_segments):
        end = min(start + segment_length, original_length)
        length = end - start
        reconstructed[start:end] += segments[i, 0, :length]
        counts[start:end] += 1
        start += stride
    
    # é¿å…é™¤é›¶
    counts = np.maximum(counts, 1)
    reconstructed = reconstructed / counts
    
    return reconstructed


def inference_single_file(
    model,
    input_path,
    output_path,
    device='cuda',
    segment_length=2048,
    stride=1024,
    normalize='zscore',
    batch_size=32,
    save_format='npy'
):
    """
    å¯¹å•ä¸ªæ–‡ä»¶è¿›è¡Œæ¨ç†
    
    Args:
        model: æ¨¡å‹
        input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„ (.npy)
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        device: è®¾å¤‡
        segment_length: åˆ†å‰²é•¿åº¦
        stride: æ»‘çª—æ­¥é•¿
        normalize: å½’ä¸€åŒ–æ–¹æ³•
        batch_size: æ‰¹å¤„ç†å¤§å°
        save_format: ä¿å­˜æ ¼å¼ ('npy', 'npz', 'txt')
    
    Returns:
        stats: æ¨ç†ç»Ÿè®¡ä¿¡æ¯
    """
    # åŠ è½½ä¿¡å·
    signal = np.load(input_path)
    if signal.ndim == 2:
        signal = signal[0, :]  # å–ç¬¬ä¸€ä¸ªé€šé“
    
    original_length = len(signal)
    
    # å½’ä¸€åŒ–
    signal_norm, norm_stats = normalize_signal(signal, method=normalize)
    
    # åˆ†å‰²
    segments, num_segments, actual_length = segment_signal(
        signal_norm, segment_length, stride
    )
    
    # æ‰¹é‡æ¨ç†
    denoised_segments = []
    
    with torch.no_grad():
        for i in range(0, num_segments, batch_size):
            batch = segments[i:i + batch_size]
            batch_tensor = torch.from_numpy(batch).float().to(device)
            
            outputs = model(batch_tensor)
            y_hat = outputs['y_hat'].cpu().numpy()
            
            denoised_segments.append(y_hat)
    
    denoised_segments = np.concatenate(denoised_segments, axis=0)
    
    # é‡å»ºå®Œæ•´ä¿¡å·
    denoised_signal = reconstruct_signal(
        denoised_segments, actual_length, stride
    )
    
    # åå½’ä¸€åŒ–
    denoised_signal = denormalize_signal(denoised_signal, norm_stats)
    
    # æˆªå–åˆ°åŸå§‹é•¿åº¦
    denoised_signal = denoised_signal[:original_length]
    
    # ä¿å­˜
    output_path = Path(output_path)
    output_path.parent.mkdir(exist_ok=True, parents=True)
    
    if save_format == 'npy':
        np.save(output_path, denoised_signal)
    elif save_format == 'npz':
        np.savez(
            output_path,
            denoised=denoised_signal,
            original=signal,
            metadata={'num_segments': num_segments, 'stride': stride}
        )
    elif save_format == 'txt':
        np.savetxt(output_path, denoised_signal)
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    mse = np.mean((signal - denoised_signal) ** 2)
    
    stats = {
        'input_file': str(input_path),
        'output_file': str(output_path),
        'original_length': original_length,
        'num_segments': num_segments,
        'mse': float(mse),
        'signal_std': float(np.std(signal)),
        'denoised_std': float(np.std(denoised_signal))
    }
    
    return stats


def inference_directory(
    model,
    input_dir,
    output_dir,
    device='cuda',
    segment_length=2048,
    stride=1024,
    normalize='zscore',
    batch_size=32,
    save_format='npy',
    pattern='*.npy'
):
    """
    å¯¹ç›®å½•å†…æ‰€æœ‰æ–‡ä»¶è¿›è¡Œæ‰¹é‡æ¨ç†
    
    Args:
        model: æ¨¡å‹
        input_dir: è¾“å…¥ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        device: è®¾å¤‡
        segment_length: åˆ†å‰²é•¿åº¦
        stride: æ»‘çª—æ­¥é•¿
        normalize: å½’ä¸€åŒ–æ–¹æ³•
        batch_size: æ‰¹å¤„ç†å¤§å°
        save_format: ä¿å­˜æ ¼å¼
        pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼
    
    Returns:
        all_stats: æ‰€æœ‰æ–‡ä»¶çš„ç»Ÿè®¡ä¿¡æ¯åˆ—è¡¨
    """
    input_dir = Path(input_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True, parents=True)
    
    # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶
    input_files = sorted(input_dir.glob(pattern))
    
    if len(input_files) == 0:
        print(f"âš ï¸  No files found matching pattern '{pattern}' in {input_dir}")
        return []
    
    print(f"\nğŸ” Found {len(input_files)} files to process")
    
    all_stats = []
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for input_path in tqdm(input_files, desc="Processing files"):
        try:
            # æ„å»ºè¾“å‡ºè·¯å¾„
            relative_path = input_path.relative_to(input_dir)
            output_path = output_dir / relative_path.stem
            
            if save_format == 'npy':
                output_path = output_path.with_suffix('.npy')
            elif save_format == 'npz':
                output_path = output_path.with_suffix('.npz')
            elif save_format == 'txt':
                output_path = output_path.with_suffix('.txt')
            
            # æ¨ç†
            stats = inference_single_file(
                model=model,
                input_path=input_path,
                output_path=output_path,
                device=device,
                segment_length=segment_length,
                stride=stride,
                normalize=normalize,
                batch_size=batch_size,
                save_format=save_format
            )
            
            all_stats.append(stats)
            
        except Exception as e:
            print(f"\nâŒ Error processing {input_path.name}: {str(e)}")
            continue
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats_path = output_dir / 'inference_stats.json'
    with open(stats_path, 'w') as f:
        json.dump(all_stats, f, indent=2)
    
    print(f"\nâœ“ Processed {len(all_stats)} files")
    print(f"âœ“ Statistics saved to: {stats_path}")
    
    # æ‰“å°æ±‡æ€»ç»Ÿè®¡
    if all_stats:
        avg_mse = np.mean([s['mse'] for s in all_stats])
        print(f"\nğŸ“Š Summary:")
        print(f"  - Average MSE: {avg_mse:.6f}")
        print(f"  - Total files: {len(all_stats)}")
    
    return all_stats


def parse_args():
    parser = argparse.ArgumentParser(description="File-level inference for EEG denoising")
    
    # æ¨¡å‹é…ç½®
    parser.add_argument("--checkpoint", type=str, required=True,
                        help="æ¨¡å‹checkpointè·¯å¾„")
    parser.add_argument("--device", type=str, default="cuda",
                        help="è®¾å¤‡ (cuda/cpu)")
    
    # è¾“å…¥/è¾“å‡ºé…ç½®
    parser.add_argument("--input", type=str, required=True,
                        help="è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„")
    parser.add_argument("--output", type=str, required=True,
                        help="è¾“å‡ºæ–‡ä»¶æˆ–ç›®å½•è·¯å¾„")
    parser.add_argument("--pattern", type=str, default="*.npy",
                        help="æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆä»…ç›®å½•æ¨¡å¼ï¼‰")
    
    # æ¨ç†å‚æ•°
    parser.add_argument("--segment_length", type=int, default=2048,
                        help="åˆ†å‰²é•¿åº¦")
    parser.add_argument("--stride", type=int, default=1024,
                        help="æ»‘çª—æ­¥é•¿ï¼ˆå»ºè®®ä¸ºsegment_lengthçš„ä¸€åŠï¼‰")
    parser.add_argument("--normalize", type=str, default="zscore",
                        choices=['zscore', 'minmax', 'none'],
                        help="å½’ä¸€åŒ–æ–¹æ³•")
    parser.add_argument("--batch_size", type=int, default=32,
                        help="æ‰¹å¤„ç†å¤§å°")
    parser.add_argument("--save_format", type=str, default="npy",
                        choices=['npy', 'npz', 'txt'],
                        help="ä¿å­˜æ ¼å¼")
    
    return parser.parse_args()


def main():
    args = parse_args()
    
    # æ‰“å°é…ç½®
    print("=" * 70)
    print("EEG Denoising - File-level Inference")
    print("=" * 70)
    print(f"Checkpoint: {args.checkpoint}")
    print(f"Input: {args.input}")
    print(f"Output: {args.output}")
    print(f"Device: {args.device}")
    print(f"Segment length: {args.segment_length}")
    print(f"Stride: {args.stride}")
    print(f"Normalize: {args.normalize}")
    print(f"Batch size: {args.batch_size}")
    print(f"Save format: {args.save_format}")
    print("=" * 70)
    
    # è®¾å¤‡
    device = torch.device(args.device if torch.cuda.is_available() else "cpu")
    if args.device == "cuda" and not torch.cuda.is_available():
        print("âš ï¸  CUDA not available, using CPU")
    
    # åŠ è½½æ¨¡å‹
    model, cfg = load_model(args.checkpoint, device=device)
    
    # åˆ¤æ–­æ˜¯æ–‡ä»¶è¿˜æ˜¯ç›®å½•
    input_path = Path(args.input)
    
    if input_path.is_file():
        # å•æ–‡ä»¶æ¨ç†
        print("\nğŸ“„ Single file mode")
        stats = inference_single_file(
            model=model,
            input_path=input_path,
            output_path=args.output,
            device=device,
            segment_length=args.segment_length,
            stride=args.stride,
            normalize=args.normalize,
            batch_size=args.batch_size,
            save_format=args.save_format
        )
        
        print("\nâœ“ Inference completed!")
        print(f"  - Input: {stats['input_file']}")
        print(f"  - Output: {stats['output_file']}")
        print(f"  - Original length: {stats['original_length']:,} samples")
        print(f"  - Num segments: {stats['num_segments']}")
        print(f"  - MSE: {stats['mse']:.6f}")
        
    elif input_path.is_dir():
        # ç›®å½•æ‰¹é‡æ¨ç†
        print("\nğŸ“ Directory mode")
        all_stats = inference_directory(
            model=model,
            input_dir=input_path,
            output_dir=args.output,
            device=device,
            segment_length=args.segment_length,
            stride=args.stride,
            normalize=args.normalize,
            batch_size=args.batch_size,
            save_format=args.save_format,
            pattern=args.pattern
        )
        
        print("\nâœ“ Batch inference completed!")
        
    else:
        print(f"âŒ Error: Input path '{input_path}' does not exist")
        return
    
    print("\n" + "=" * 70)


if __name__ == "__main__":
    main()
