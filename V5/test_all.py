"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - éªŒè¯æ‰€æœ‰æ¨¡å—
æ— éœ€çœŸå®žæ•°æ®é›†ï¼Œä½¿ç”¨éšæœºæ•°æ®
"""
import sys
from pathlib import Path
import torch

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

print("\n" + "="*70)
print("UAR-ACSSNet æ¨¡å—æµ‹è¯•")
print("="*70 + "\n")

# ==========================================
# 1. æµ‹è¯• STFT å¤„ç†å™¨
# ==========================================
print("1ï¸âƒ£  æµ‹è¯• STFT å¤„ç†å™¨...")
from signal_processing import STFTProcessor

stft_proc = STFTProcessor()
x_test = torch.randn(2, 1, 2048)
S_test = stft_proc(x_test)

print(f"   âœ“ STFT: {x_test.shape} â†’ {S_test.shape}")
print(f"   âœ“ é¢‘çŽ‡ bins: {stft_proc.num_freq_bins}")
print(f"   âœ“ é¢‘çŽ‡èŒƒå›´: [{stft_proc.k_min * stft_proc.df:.2f}, {stft_proc.k_max * stft_proc.df:.2f}] Hz\n")

# ==========================================
# 2. æµ‹è¯•æ•°æ®é›†ï¼ˆä½¿ç”¨ä¸´æ—¶ç›®å½•ï¼‰
# ==========================================
print("2ï¸âƒ£  æµ‹è¯•æ•°æ®é›†æ¨¡å—...")
import tempfile
import numpy as np
from datasets import EEGPairDataset

# åˆ›å»ºä¸´æ—¶æ•°æ®é›†
with tempfile.TemporaryDirectory() as tmpdir:
    tmpdir = Path(tmpdir)
    
    # åˆ›å»ºç›®å½•ç»“æž„
    for split in ["train", "val", "test"]:
        (tmpdir / split / "raw").mkdir(parents=True)
        (tmpdir / split / "clean").mkdir(parents=True)
        
        # ç”Ÿæˆå‡æ•°æ®
        for i in range(3):
            fname = f"{i:04d}.npy"
            np.save(tmpdir / split / "raw" / fname, np.random.randn(3000).astype(np.float32))
            np.save(tmpdir / split / "clean" / fname, np.random.randn(3000).astype(np.float32))
    
    # æµ‹è¯•æ•°æ®é›†
    ds = EEGPairDataset(
        root=str(tmpdir),
        split="train",
        segment_length=2048,
        random_crop=True,
        normalize="zscore_per_sample",
        return_meta=True,
    )
    
    x_raw, x_clean, meta = ds[0]
    print(f"   âœ“ Dataset length: {len(ds)}")
    print(f"   âœ“ Sample shape: {x_raw.shape}, {x_clean.shape}")
    print(f"   âœ“ Meta keys: {list(meta.keys())}\n")

# ==========================================
# 3. æµ‹è¯•æ¨¡åž‹
# ==========================================
print("3ï¸âƒ£  æµ‹è¯• UAR-ACSSNet æ¨¡åž‹...")
from models import UAR_ACSSNet

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"   Using device: {device}")

model = UAR_ACSSNet(
    segment_length=2048,
    unet_base_ch=32,
    unet_levels=4,
    spec_channels=64,
    acss_depth=3,
    num_freq_bins=103,
    dropout=0.1,
).to(device)

total_params = sum(p.numel() for p in model.parameters())
print(f"   âœ“ Total parameters: {total_params:,}")

# å‰å‘ä¼ æ’­
x_input = torch.randn(2, 1, 2048).to(device)

print(f"\n  Running forward pass (scan sanity checks will trigger)...")
with torch.no_grad():
    outputs = model(x_input)

print(f"\n   âœ“ Forward pass completed")
print(f"   Output type: {type(outputs)}")
if isinstance(outputs, dict):
    print(f"   Output keys: {list(outputs.keys())}")
    print(f"   Details:")
    for k, v in outputs.items():
        print(f"     - {k}: {v.shape}, range=[{v.min():.3f}, {v.max():.3f}]")
        if k == 'w':
            print(f"       w stats: min={v.min():.4f}, max={v.max():.4f}, mean={v.mean():.4f}, std={v.std():.4f}")
else:
    print(f"   âš  Warning: Expected dict output, got {type(outputs)}")
print()

# ==========================================
# 4. æµ‹è¯•æŸå¤±å‡½æ•°
# ==========================================
print("4ï¸âƒ£  æµ‹è¯•æŸå¤±å‡½æ•°...")
from train import compute_losses

batch = (x_input, torch.randn(2, 1, 2048).to(device))
cfg = {
    "charbonnier_eps": 1e-6,
    "use_weighted_recon": False,
    "tv_weight": 0.01,
    "entropy_weight": 0.01,
    "recon_weight": 1.0,
    "conf_reg_weight": 0.1,
    "consistency_weight": 0.0,
}

losses = compute_losses(batch, outputs, cfg)

print(f"   âœ“ Losses computed:")
for k, v in losses.items():
    print(f"     - {k}: {v.item():.6f}")
print()

# ==========================================
# 5. æµ‹è¯•è®­ç»ƒå¾ªçŽ¯ï¼ˆ1 stepï¼‰
# ==========================================
print("5ï¸âƒ£  æµ‹è¯•è®­ç»ƒæ­¥éª¤...")
from torch.utils.data import TensorDataset, DataLoader

# åˆ›å»ºå‡æ•°æ®åŠ è½½å™¨
dummy_ds = TensorDataset(
    torch.randn(16, 1, 2048),
    torch.randn(16, 1, 2048)
)
dummy_loader = DataLoader(dummy_ds, batch_size=4, shuffle=True)

# ä¼˜åŒ–å™¨
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)

# è®­ç»ƒä¸€æ­¥
model.train()
batch = next(iter(dummy_loader))
x_raw, x_clean = [b.to(device) for b in batch]

outputs = model(x_raw)
losses = compute_losses((x_raw, x_clean), outputs, cfg)
loss = losses["total"]

optimizer.zero_grad()
loss.backward()
optimizer.step()

print(f"   âœ“ Training step completed")
print(f"     - Loss: {loss.item():.6f}\n")

# ==========================================
# 6. å½¢çŠ¶å’ŒèŒƒå›´æ£€æŸ¥
# ==========================================
print("6ï¸âƒ£  å½¢çŠ¶å’ŒèŒƒå›´æ£€æŸ¥...")

# Shape assertions
assert outputs['y_hat'].shape == (x_raw.shape[0], 1, 2048), "y_hat shape mismatch"
assert outputs['w'].shape == (x_raw.shape[0], 1, 2048), "w shape mismatch"
assert outputs['g_freq'].shape[1] == 1, "g_freq channel mismatch"

# Range assertions
w_val = outputs['w']
assert (w_val >= 0).all() and (w_val <= 1.01).all(), "w out of range [0,1]"

print(f"   âœ“ All shape assertions passed")
print(f"   âœ“ All range assertions passed")

# è¯¦ç»†çš„ w ç»Ÿè®¡æ£€æŸ¥
print(f"\n   Confidence map (w) detailed check:")
print(f"     min:  {w_val.min():.6f}")
print(f"     max:  {w_val.max():.6f}")
print(f"     mean: {w_val.mean():.6f}")
print(f"     std:  {w_val.std():.6f}")

# é€€åŒ–æ£€æŸ¥
warnings = []
if 0.49 < w_val.mean() < 0.51:
    warnings.append("w.mean() very close to 0.5")
if w_val.std() < 0.01:
    warnings.append("w.std() very small (< 0.01)")
if w_val.min() > 0.4 and w_val.max() < 0.6:
    warnings.append("w range very narrow [0.4, 0.6]")

if warnings:
    print(f"   âš  Potential issues detected:")
    for w in warnings:
        print(f"     - {w}")
else:
    print(f"   âœ“ w statistics look healthy")
print()

# ==========================================
# æ€»ç»“
# ==========================================
print("="*70)
print("âœ… æ‰€æœ‰æ¨¡å—æµ‹è¯•é€šè¿‡ï¼")
print("="*70)
print("\nðŸ“ ä¸‹ä¸€æ­¥:")
print("   1. å‡†å¤‡çœŸå®žæ•°æ®é›†ï¼ˆDataset/train/val/test/raw/clean/*.npyï¼‰")
print("   2. è¿è¡Œ: python main.py --dataset_root <path> --quick_test")
print("   3. å®Œæ•´è®­ç»ƒ: python main.py --dataset_root <path> --num_epochs 50")
print("\n" + "="*70 + "\n")
